{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66bb4cc4",
   "metadata": {
    "id": "aa2c1ada"
   },
   "source": [
    "# Welcome to ConceptsDreambooth v1.2 Optimized! \n",
    "\n",
    "Your refined and continually updated guide to training an artstyle. We're currently using the 1.4 model as it suits our needs best. \n",
    "\n",
    "Notebook by Shane Deir (Visit https://www.reddit.com/r/ConceptStream/ for more useful tools in the future)\n",
    "\n",
    "### Instructions:\n",
    "\n",
    "Welcome netsculptor! Today is the day you start your journey into the new world of infinite creation. You no longer need a robe and ancient staff to indulge in magic.\n",
    "\n",
    "I've put together this notebook to give you easy access to the entire process of training your own incredible artstyle from start to finish. \n",
    "\n",
    "Since you're here, I'm going to assume that you already have this notebook open on a cloud-instance. (Ignore anything about the cloud if you're training on your own GPU)\n",
    "\n",
    "Requirements: \n",
    "\n",
    "ConceptsDreambooth now works flawlessly on any GPU with at least 24GB of VRAM. \n",
    "                                                                                                         \n",
    "Remember this one rule: \n",
    "\n",
    "Have fun and enjoy the process. You're about to create something that humanity has never experienced before. \n",
    "                                                                                                  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7849210b",
   "metadata": {
    "id": "7b971cc0"
   },
   "source": [
    "## Step 1) Build your environment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014a0085",
   "metadata": {
    "id": "2AsGA1xpNQnb"
   },
   "source": [
    "Run the cell below (click into it and press the play button, or shift+enter) to install all the dependencies we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e3dd19",
   "metadata": {
    "id": "9e1bc458-091b-42f4-a125-c3f0df20f29d",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Build your environment\n",
    "!pip install omegaconf\n",
    "!pip install einops\n",
    "!pip install pytorch-lightning==1.6.5\n",
    "!pip install test-tube\n",
    "!pip install transformers\n",
    "!pip install kornia\n",
    "!pip install -e git+https://github.com/CompVis/taming-transformers.git@master#egg=taming-transformers\n",
    "!pip install -e git+https://github.com/openai/CLIP.git@main#egg=clip\n",
    "!pip install setuptools==59.5.0\n",
    "!pip install pillow==9.0.1\n",
    "!pip install torchmetrics==0.6.0\n",
    "!pip install -e .\n",
    "!pip install protobuf==3.20.1\n",
    "!pip install gdown\n",
    "!pip install -qq diffusers[\"training\"]==0.3.0 transformers ftfy\n",
    "!pip install -qq \"ipywidgets>=7,<8\"\n",
    "!pip install huggingface_hub\n",
    "!pip install ipywidgets==7.7.1\n",
    "!pip install captionizer==1.0.1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f6a2ef",
   "metadata": {},
   "source": [
    "## Step 2) Download the Stable Diffusion 1.4 Model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da0712b",
   "metadata": {},
   "source": [
    "You'll need to sign up for an account with Hugging Face and agree to their terms if you haven't already. Run the cell below (If you're on runpod you may get a Javascript error, just refresh the page and it will work), you'll be asked to input an access token. You can find this in your hugging face account settings, then access tokens. Paste it into the box and select login. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4cc05c4",
   "metadata": {
    "id": "dae11c10"
   },
   "outputs": [],
   "source": [
    "# Hugging Face Login\n",
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f481aa6",
   "metadata": {},
   "source": [
    "Now that you've authenticated your access token, run the cell below to download the Stable Diffusion 1.4 model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5afd45bf",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Download the 1.4 sd model\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from huggingface_hub import hf_hub_download\n",
    "downloaded_model_path = hf_hub_download(\n",
    " repo_id=\"CompVis/stable-diffusion-v-1-4-original\",\n",
    " filename=\"sd-v1-4.ckpt\",\n",
    " use_auth_token=True\n",
    ")\n",
    "\n",
    "# Move the sd-v1-4.ckpt to the root of this directory as \"model.ckpt\"\n",
    "actual_locations_of_model_blob = !readlink -f {downloaded_model_path}\n",
    "!mv {actual_locations_of_model_blob[-1]} model.ckpt\n",
    "clear_output()\n",
    "print(\"âœ… model.ckpt successfully downloaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878ea872",
   "metadata": {
    "id": "17d1d11a"
   },
   "source": [
    "## Step 3) Regularization Images (These are very important)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78eeeab",
   "metadata": {
    "id": "ed07a5df"
   },
   "source": [
    "Run the cell below to download 1000 pre-generated artstyle regularization images. Downloading these instead of generating them will save you several hours. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea63623a",
   "metadata": {
    "id": "e7EydXCjOV1v"
   },
   "outputs": [],
   "source": [
    "# Download the regularization images.\n",
    "!git clone https://github.com/ShaneDeir/ConceptStream_regularization_images/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0605e39",
   "metadata": {},
   "source": [
    "When that's finished run the cell below to move them into the proper directory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180b87e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move the regularization images.\n",
    "import shutil\n",
    "\n",
    "original = r'/workspace/ConceptsDreambooth/ConceptStream_regularization_images/'\n",
    "target = r'/workspace/ConceptsDreambooth/regularization_images'\n",
    "\n",
    "shutil.move(original, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a5631c",
   "metadata": {},
   "source": [
    "Only use the next two cells if you're experimenting with the amount of regularization images used for training. The cells below are optional and will allow you to generate an additional 1000 artstyle regularization images. Adjust the code accordingly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c9b2d4",
   "metadata": {
    "id": "67f9ff0c-b529-4c7c-8e26-8388d70a5d91"
   },
   "outputs": [],
   "source": [
    "# Skip this cell and the next one if you downloaded the regularization images.\n",
    "\n",
    "# Generate 1000 artstyle images.\n",
    "self_generated_files_prompt = \"artstyle\" #@param {type:\"string\"}\n",
    "self_generated_files_count = 1000 #@param {type:\"integer\"}\n",
    "\n",
    "!python scripts/stable_txt2img.py \\\n",
    " --seed 10 \\\n",
    " --ddim_eta 0.0 \\\n",
    " --n_samples 1 \\\n",
    " --n_iter {self_generated_files_count} \\\n",
    " --scale 10.0 \\\n",
    " --ddim_steps 50 \\\n",
    " --ckpt model.ckpt \\\n",
    " --prompt {self_generated_files_prompt}\n",
    "\n",
    "dataset=self_generated_files_prompt\n",
    "\n",
    "!mkdir -p regularization_images/{dataset}\n",
    "!mv outputs/txt2img-samples/*.png regularization_images/{dataset}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275fd74c",
   "metadata": {
    "id": "3d1c7e1c"
   },
   "outputs": [],
   "source": [
    "# Zip up the files for downloading and reuse.\n",
    "# Download this file locally so you can reuse during another training on this dataset.\n",
    "!apt-get install -y zip\n",
    "!zip -r regularization_images.zip regularization_images/{dataset}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9830be",
   "metadata": {},
   "source": [
    "## Step 4) Upload your training images.\n",
    "So here you have 2 options: \n",
    "\n",
    "1) You can directly upload a folder named \"training_images\" filled with your images in:\n",
    "\n",
    "        /workspace/ConceptsDreambooth/\n",
    "        \n",
    "So when you're done uploading you should see all of your training images in:\n",
    "\n",
    "        /workspace/ConceptsDreambooth/training_images/\n",
    "        \n",
    "  OR\n",
    "  \n",
    "2) You can upload your images to imgur and follow the instructions in the next two cells.\n",
    "\n",
    "\n",
    "\n",
    "### CAUTION: \n",
    "\n",
    "Be sure to upload an even amount of training images. Otherwise things may fall apart. \n",
    "\n",
    "*  Be sure to use at least 30 images with dimensions 512px X 512px. \n",
    "*  Use your artistic vision when choosing your training images. \n",
    "*  Treat the model with respect.\n",
    "\n",
    "## Hot Tip\n",
    "\n",
    "Use https://www.birme.net/?target_width=512&target_height=512 to bulk resize your images to the proper dimensions! \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf18e81",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Enter your urls below if you pulling from imgur suits your needs. It's much easier to just upload a folder. \n",
    "# This is here so it's easier to hotswap datasets between multiple people for refined testing. \n",
    "\n",
    "urls = [\n",
    " \"https://i.imgur.com/test1.png\",\n",
    " \"https://i.imgur.com/test2.png\",\n",
    " \"https://i.imgur.com/test3.png\",\n",
    " \"https://i.imgur.com/test4.png\",\n",
    " \"https://i.imgur.com/test5.png\",\n",
    " # Place as many links as you want here in the format displayed above.\n",
    " # Make sure they have the .png extension in the url.\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a842e3",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell will download your images and place them into a grid.\n",
    "# The grid is unlikely to work (Which is totally fine) if you have more than 30 images (Which you should). \n",
    "\n",
    "import os\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def image_grid(imgs, rows, cols):\n",
    " assert len(imgs) == rows*cols\n",
    "\n",
    " w, h = imgs[0].size\n",
    " grid = Image.new('RGB', size=(cols*w, rows*h))\n",
    " grid_w, grid_h = grid.size\n",
    "\n",
    " for i, img in enumerate(imgs):\n",
    "  grid.paste(img, box=(i%cols*w, i//cols*h))\n",
    " return grid\n",
    "\n",
    "def download_image(url):\n",
    " try:\n",
    "  response = requests.get(url)\n",
    " except:\n",
    "  return None\n",
    " return Image.open(BytesIO(response.content)).convert(\"RGB\")\n",
    "\n",
    "images = list(filter(None,[download_image(url) for url in urls]))\n",
    "save_path = \"./training_images\"\n",
    "if not os.path.exists(save_path):\n",
    " os.mkdir(save_path)\n",
    "[image.save(f\"{save_path}/{i}.png\", format=\"png\") for i, image in enumerate(images)]\n",
    "image_grid(images, 1, len(images))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7c9e63",
   "metadata": {},
   "source": [
    "## Step 5) Training Steps & Time and Cost Calculator."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e98d7e",
   "metadata": {},
   "source": [
    "Run the cell below to set your training steps using the optimized formula. (credit to Reddit user u/RealAstropulse for the idea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53a0b990",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: '/workspace/ConceptsDreambooth/training_images/'",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[1;36m(most recent call last)\u001b[0m:\n",
      "\u001b[1;36m  Cell \u001b[1;32mIn [1], line 10\u001b[1;36m\n\u001b[1;33m    for path in os.listdir(dir_path):\u001b[1;36m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m\u001b[1;31m:\u001b[0m [WinError 3] The system cannot find the path specified: '/workspace/ConceptsDreambooth/training_images/'\n"
     ]
    }
   ],
   "source": [
    "# Training steps formula.\n",
    "\n",
    "import os\n",
    "\n",
    "# Training images folder path. \n",
    "dir_path = r'/workspace/ConceptsDreambooth/training_images/'\n",
    "# Make sure your training images are in the \"/workspace/ConceptsDreambooth/training_images\" folder.\n",
    "training_image_count = 0\n",
    "# Iterate directory\n",
    "for path in os.listdir(dir_path):\n",
    "    # check if current path is a file\n",
    "    if os.path.isfile(os.path.join(dir_path, path)):\n",
    "        training_image_count += 1\n",
    "\n",
    "max_training_steps = training_image_count * 50 + 800\n",
    "\n",
    "print(\"You have\", training_image_count, \"training images in your folder. Make sure this is an even number.\")\n",
    "\n",
    "print(\"Your total max training steps are now set to:\", max_training_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00aef87e",
   "metadata": {},
   "source": [
    "Run the cell below to get an estimate of:\n",
    "\n",
    "1) How long it will take to train.\n",
    "2) How much it will cost.\n",
    "\n",
    "You'll be asked to input your price per hour. If you make a mistake you can always run the cell again. You can also add or remove training images to adjust your time and cost, just be sure to run the cell above again after doing that. \n",
    "\n",
    "These estimates are based around training on an Nvidia RTX A6000. As such, they're less likely to be accurate on an RTX 3090. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04ba257b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "How much does your GPU rental cost per hour?: $ 0.559\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'max_training_steps' is not defined",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[1;36m(most recent call last)\u001b[0m:\n",
      "\u001b[1;36m  Cell \u001b[1;32mIn [2], line 6\u001b[1;36m\n\u001b[1;33m    time_estimate = max_training_steps / 2100\u001b[1;36m\n",
      "\u001b[1;31mNameError\u001b[0m\u001b[1;31m:\u001b[0m name 'max_training_steps' is not defined\n"
     ]
    }
   ],
   "source": [
    "# Cost calculation user input.\n",
    "training_cost = input(\"How much does your GPU rental cost per hour?: $\")\n",
    "training_cost = float(training_cost)\n",
    "\n",
    "# Time estimate on an RTX A6000 (2100 derived through testing).\n",
    "time_estimate = max_training_steps / 2100\n",
    "\n",
    "# Convert hours in float format into HH:MM format. \n",
    "minutes = time_estimate*60\n",
    "hours, minutes = divmod(minutes, 60)\n",
    "\n",
    "# Displays the time estimate.\n",
    "print(\"Your training time estimate is: \",\n",
    "      (\"%02d:%02d\"%(hours,minutes)), \"(HH:MM)\")\n",
    "\n",
    "# Displays the cost estimate.\n",
    "print(\"The total cost to train this neural network should be around $\", round(training_cost * time_estimate, 2),\".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcfba79c",
   "metadata": {
    "id": "ad4e50df"
   },
   "source": [
    "## Step 6) Training.\n",
    "\n",
    "To train them is your cause! This is the most important step of all so pay close attention. \n",
    "\n",
    "In the cell below you'll find a variable named \"token\", after the \"=\" replace the word in quotes with the name of your own artstyle. This will be the word you'll use in your prompt to summon your artstyle, so be creative with the spelling. \n",
    "\n",
    "You'll also be able to give your project a name! This is just for the filename so you can stay organized. \n",
    "\n",
    "Replace the words in the cell below and run the cell to begin training. That's it! You made it! \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37dc1a93",
   "metadata": {
    "id": "6fa5dd66-2ca0-4819-907e-802e25583ae6",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Training\n",
    "\n",
    "# Give your project a name! This is only used for the filename, so don't stress if you can't think of something cool.\n",
    "project_name = \"project_name\"\n",
    "\n",
    "# Replace the name inside the quotation marks. This token is the name of your artstyle! Get creative and make sure you choose a unique word that doesn't exist. \n",
    "token = \"PrimeUniverse\"\n",
    "\n",
    "# Don't change this one. \n",
    "class_word = \"artstyle\" \n",
    "\n",
    "\n",
    "reg_data_root = \"/workspace/ConceptsDreambooth/regularization_images/artstyle/\"\n",
    "\n",
    "!rm -rf training_images/.ipynb_checkpoints\n",
    "!python \"main.py\" \\\n",
    " --base configs/stable-diffusion/v1-finetune_unfrozen.yaml \\\n",
    " -t \\\n",
    " --actual_resume \"model.ckpt\" \\\n",
    " --reg_data_root \"{reg_data_root}\" \\\n",
    " -n \"{project_name}\" \\\n",
    " --gpus 0, \\\n",
    " --data_root \"/workspace/ConceptsDreambooth/training_images\" \\\n",
    " --max_training_steps {max_training_steps} \\\n",
    " --class_word \"{class_word}\" \\\n",
    " --token \"{token}\" \\\n",
    " --no-test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f403d7",
   "metadata": {},
   "source": [
    "## Copy and name the checkpoint file.\n",
    "\n",
    "Run the cell below after your model has finished training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1cf9c6",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Copy the checkpoint file into our \"trained_models\" folder.\n",
    "\n",
    "directory_paths = !ls -d logs/*\n",
    "last_checkpoint_file = directory_paths[-1] + \"/checkpoints/last.ckpt\"\n",
    "training_images = !find training_images/*\n",
    "date_string = !date +\"%Y-%m-%dT%H-%M-%S\"\n",
    "file_name = date_string[-1] + \"_\" + project_name + \"_\" + str(len(training_images)) + \"_training_images_\" +  str(max_training_steps) + \"_max_training_steps_\" + token + \"_token_\" + class_word + \"_class_word.ckpt\"\n",
    "\n",
    "file_name = file_name.replace(\" \", \"_\")\n",
    "\n",
    "!mkdir -p trained_models\n",
    "!mv \"{last_checkpoint_file}\" \"trained_models/{file_name}\"\n",
    "\n",
    "print(\"Download your trained model file from trained_models/\" + file_name + \" and use it in your favorite Stable Diffusion GUI or Repo!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d08c6fc",
   "metadata": {},
   "source": [
    "## How to use your trained model!\n",
    "\n",
    "The way to use your token is `<token> <class>`\n",
    "\n",
    "So we would say in our prompt \"EvenYouniverse artstyle\" to summon our trained artstyle. \n",
    "\n",
    "Where you place it in your prompt matters.\n",
    "\n",
    "Try at the start of your prompt to begin with, then reorder with experimentation at your leisure. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1b5b1b",
   "metadata": {},
   "source": [
    "## You made it all the way! \n",
    "\n",
    "Now we can run the cell below to generate some images with our trained model! Great moves, keep it up. \n",
    "Remember to download your model! \n",
    "\n",
    "Be sure to replace \"PrimeUniverse\" with your own token. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78caafde",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\GIT\\ConceptsDreambooth_2\\scripts\\stable_txt2img.py\", line 2, in <module>\n",
      "    import torch\n",
      "ModuleNotFoundError: No module named 'torch'\n"
     ]
    }
   ],
   "source": [
    "!python scripts/stable_txt2img.py \\\n",
    " --ddim_eta 0.0 \\\n",
    " --n_samples 1 \\\n",
    " --n_iter 4 \\\n",
    " --scale 7.0 \\\n",
    " --ddim_steps 50 \\\n",
    " --ckpt \"/workspace/ConceptsDreambooth/trained_models/{file_name}\" \\\n",
    " --prompt \"PrimeUniverse artstyle as Zeus, 8k resolution, intricate details, dramatic lighting, volumetric lighting, cinema 4d render\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4396e96c",
   "metadata": {},
   "source": [
    "# The Credits\n",
    "\n",
    "This repo was built upon the shoulders of giants. Let's pay them respect by continuing their work!\n",
    "\n",
    "\n",
    "Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, BjÃ¶rn Ommer: \n",
    "https://arxiv.org/abs/2112.10752\n",
    "\n",
    "Nataniel Ruiz, Yuanzhen Li, Varun Jampani, Yael Pritch, Michael Rubinstein, Kfir Aberman: \n",
    "https://arxiv.org/abs/2208.12242\n",
    "\n",
    "\n",
    "Thank you to everyone involved in the many projects that this repo and Juptyer Notebook borrows from and builds upon. \n",
    "\n",
    "You know who you are! \n",
    "\n",
    "See You Space Cowboy..."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (Spyder)",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
